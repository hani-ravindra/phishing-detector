{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2826d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial Data Exploration ---\n",
      "Dataset Shape: (549346, 2)\n",
      "\n",
      "First 5 Rows:\n",
      "                                                 URL Label\n",
      "0  nobell.it/70ffb52d079109dca5664cce6f317373782/...   bad\n",
      "1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...   bad\n",
      "2  serviciosbys.com/paypal.cgi.bin.get-into.herf....   bad\n",
      "3  mail.printakid.com/www.online.americanexpress....   bad\n",
      "4  thewhiskeydregs.com/wp-content/themes/widescre...   bad\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549346 entries, 0 to 549345\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   URL     549346 non-null  object\n",
      " 1   Label   549346 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.4+ MB\n",
      "\n",
      "Missing Values:\n",
      "URL      0\n",
      "Label    0\n",
      "dtype: int64\n",
      "\n",
      "Label Distribution:\n",
      "Label\n",
      "good    392924\n",
      "bad     156422\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Load Data\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# Load the Kaggle dataset\n",
    "kaggle_path = 'data/phishing_site_urls.csv'\n",
    "df = pd.read_csv(kaggle_path)\n",
    "\n",
    "# --- 1. Initial Exploration ---\n",
    "print(\"--- Initial Data Exploration ---\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "# --- 2. Check for Missing Values ---\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# --- 3. Analyze Label Distribution ---\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2559f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping duplicates: (549346, 2)\n",
      "Shape after dropping duplicates: (507196, 2)\n",
      "\n",
      "Dataset after cleaning and standardizing labels:\n",
      "                                                 URL  Label\n",
      "0  nobell.it/70ffb52d079109dca5664cce6f317373782/...      1\n",
      "1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...      1\n",
      "2  serviciosbys.com/paypal.cgi.bin.get-into.herf....      1\n",
      "3  mail.printakid.com/www.online.americanexpress....      1\n",
      "4  thewhiskeydregs.com/wp-content/themes/widescre...      1\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Clean and Standardize\n",
    "# --- 1. Remove Duplicates ---\n",
    "print(f\"Shape before dropping duplicates: {df.shape}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
    "\n",
    "# --- 2. Standardize Labels ---\n",
    "# We will map 'good' to 0 and 'bad' to 1\n",
    "df['Label'] = df['Label'].map({'good': 0, 'bad': 1})\n",
    "\n",
    "print(\"\\nDataset after cleaning and standardizing labels:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55ce812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining feature extraction functions...\n",
      "Functions defined. Now applying them to the dataset...\n",
      "\n",
      "Dataset with all 12 engineered features:\n",
      "                                                 URL  Label  url_length  \\\n",
      "0  nobell.it/70ffb52d079109dca5664cce6f317373782/...      1         225   \n",
      "1  www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...      1          81   \n",
      "2  serviciosbys.com/paypal.cgi.bin.get-into.herf....      1         177   \n",
      "3  mail.printakid.com/www.online.americanexpress....      1          60   \n",
      "4  thewhiskeydregs.com/wp-content/themes/widescre...      1         116   \n",
      "\n",
      "   hostname_length  dot_count  slash_count  has_ip  has_special_chars  \\\n",
      "0                0          6           10       0                  1   \n",
      "1                0          5            4       0                  1   \n",
      "2                0          7           11       0                  1   \n",
      "3                0          6            2       0                  0   \n",
      "4                0          1           10       0                  1   \n",
      "\n",
      "   subdomain_count  has_https  has_sensitive_words  directory_count  \\\n",
      "0               -1          0                    1                9   \n",
      "1               -1          0                    0                5   \n",
      "2               -1          0                    1               11   \n",
      "3               -1          0                    0                3   \n",
      "4               -1          0                    0                7   \n",
      "\n",
      "   query_param_count  is_shortened  \n",
      "0                  4             0  \n",
      "1                  0             0  \n",
      "2                  0             0  \n",
      "3                  0             0  \n",
      "4                  1             0  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Engineering Functions (UPGRADED)\n",
    "print(\"Defining feature extraction functions...\")\n",
    "\n",
    "# --- All your previous functions are still here ---\n",
    "def get_url_length(url):\n",
    "    return len(url)\n",
    "def get_hostname_length(url):\n",
    "    try: return len(urlparse(url).netloc)\n",
    "    except: return 0\n",
    "def get_dot_count(url):\n",
    "    return url.count('.')\n",
    "def get_slash_count(url):\n",
    "    return url.count('/')\n",
    "def has_ip_address(url):\n",
    "    try:\n",
    "        if re.search(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', urlparse(url).netloc): return 1\n",
    "        return 0\n",
    "    except: return 0\n",
    "def has_special_chars(url):\n",
    "    if re.search(r'[@_-]', url): return 1\n",
    "    return 0\n",
    "def get_subdomain_count(url):\n",
    "    try:\n",
    "        hostname = urlparse(url).netloc\n",
    "        return len(hostname.split('.')) - 2\n",
    "    except: return 0\n",
    "def has_https(url):\n",
    "    try:\n",
    "        if urlparse(url).scheme == 'https': return 1\n",
    "        return 0\n",
    "    except: return 0\n",
    "def has_sensitive_keywords(url):\n",
    "    keywords = ['login', 'secure', 'account', 'verify', 'password', 'signin', 'banking']\n",
    "    for keyword in keywords:\n",
    "        if keyword in url.lower():\n",
    "            return 1\n",
    "    return 0\n",
    "    \n",
    "# --- NEW, SMARTER FUNCTIONS ---\n",
    "# 10. Count of Directories in Path\n",
    "def count_directories(url):\n",
    "    try:\n",
    "        path = urlparse(url).path\n",
    "        # Count non-empty segments\n",
    "        return len([segment for segment in path.split('/') if segment])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 11. Count of Query Parameters\n",
    "def count_query_params(url):\n",
    "    try:\n",
    "        query = urlparse(url).query\n",
    "        if not query:\n",
    "            return 0\n",
    "        return len(query.split('&'))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 12. Check for common URL shortening services\n",
    "def is_shortened(url):\n",
    "    shorteners = ['bit.ly', 't.co', 'goo.gl', 'tinyurl', 'ow.ly']\n",
    "    try:\n",
    "        hostname = urlparse(url).netloc\n",
    "        for shortener in shorteners:\n",
    "            if shortener in hostname:\n",
    "                return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "print(\"Functions defined. Now applying them to the dataset...\")\n",
    "\n",
    "# --- Apply ALL functions ---\n",
    "# (Old features)\n",
    "df['url_length'] = df['URL'].apply(get_url_length)\n",
    "df['hostname_length'] = df['URL'].apply(get_hostname_length)\n",
    "df['dot_count'] = df['URL'].apply(get_dot_count)\n",
    "df['slash_count'] = df['URL'].apply(get_slash_count)\n",
    "df['has_ip'] = df['URL'].apply(has_ip_address)\n",
    "df['has_special_chars'] = df['URL'].apply(has_special_chars)\n",
    "df['subdomain_count'] = df['URL'].apply(get_subdomain_count)\n",
    "df['has_https'] = df['URL'].apply(has_https)\n",
    "df['has_sensitive_words'] = df['URL'].apply(has_sensitive_keywords)\n",
    "# (New features)\n",
    "df['directory_count'] = df['URL'].apply(count_directories)\n",
    "df['query_param_count'] = df['URL'].apply(count_query_params)\n",
    "df['is_shortened'] = df['URL'].apply(is_shortened)\n",
    "\n",
    "print(\"\\nDataset with all 12 engineered features:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8719502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final feature-rich dataset saved to 'processed_features.csv'\n",
      "Final dataset head:\n",
      "   url_length  hostname_length  dot_count  slash_count  has_ip  \\\n",
      "0         225                0          6           10       0   \n",
      "1          81                0          5            4       0   \n",
      "2         177                0          7           11       0   \n",
      "3          60                0          6            2       0   \n",
      "4         116                0          1           10       0   \n",
      "\n",
      "   has_special_chars  subdomain_count  has_https  has_sensitive_words  \\\n",
      "0                  1               -1          0                    1   \n",
      "1                  1               -1          0                    0   \n",
      "2                  1               -1          0                    1   \n",
      "3                  0               -1          0                    0   \n",
      "4                  1               -1          0                    0   \n",
      "\n",
      "   directory_count  query_param_count  is_shortened  Label  \n",
      "0                9                  4             0      1  \n",
      "1                5                  0             0      1  \n",
      "2               11                  0             0      1  \n",
      "3                3                  0             0      1  \n",
      "4                7                  1             0      1  \n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create and Save Final Dataset (UPGRADED)\n",
    "# Select all our engineered features and the label\n",
    "features = [\n",
    "    'url_length', 'hostname_length', 'dot_count', 'slash_count',\n",
    "    'has_ip', 'has_special_chars', 'subdomain_count', 'has_https',\n",
    "    'has_sensitive_words', 'directory_count', 'query_param_count', 'is_shortened' # <-- Added new features\n",
    "]\n",
    "X = df[features]\n",
    "y = df['Label']\n",
    "\n",
    "# Combine features and label into a final dataframe\n",
    "final_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Save to a new CSV file, overwriting the old one\n",
    "output_path = 'processed_features.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal feature-rich dataset saved to '{output_path}'\")\n",
    "print(\"Final dataset head:\")\n",
    "print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
